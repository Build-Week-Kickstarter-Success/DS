{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "from helper_functions import load_data\n",
    "from helper_functions import my_split\n",
    "from helper_functions import downsample_majority\n",
    "from helper_functions import model_prep\n",
    "from helper_functions import get_results\n",
    "from helper_functions import get_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                name  \\\n0                                drawing for dollars   \n1  Sponsor Dereck Blackburn (Lostwars) Artist in ...   \n2                                      Mr. Squiggles   \n3                     Help me write my second novel.   \n4             Support casting my sculpture in bronze   \n\n                                                desc    goal  \\\n0  I like drawing pictures. and then i color them...    20.0   \n1  I, Dereck Blackburn will be taking upon an inc...   300.0   \n2  So I saw darkpony's successfully funded drawin...    30.0   \n3  Do your part to help out starving artists and ...   500.0   \n4  I'm nearing completion on a sculpture, current...  2000.0   \n\n   disable_communication country currency             deadline  \\\n0                      0      US      USD  2009-05-03 02:59:59   \n1                      0      US      USD  2009-05-15 19:10:00   \n2                      0      US      USD  2009-05-22 17:26:00   \n3                      0      US      USD  2009-05-28 20:09:00   \n4                      0      US      USD  2009-05-31 07:38:00   \n\n           launched_at  final_status  campaign_length  launch_year  \\\n0  2009-04-24 15:52:03             1                8         2009   \n1  2009-04-28 23:26:32             0               17         2009   \n2  2009-05-12 17:39:58             0               10         2009   \n3  2009-04-28 20:58:50             1               30         2009   \n4  2009-05-01 08:22:21             0               30         2009   \n\n   launch_month  launch_day  launch_weekday  \n0             4          24               4  \n1             4          28               1  \n2             5          12               1  \n3             4          28               1  \n4             5           1               4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>desc</th>\n      <th>goal</th>\n      <th>disable_communication</th>\n      <th>country</th>\n      <th>currency</th>\n      <th>deadline</th>\n      <th>launched_at</th>\n      <th>final_status</th>\n      <th>campaign_length</th>\n      <th>launch_year</th>\n      <th>launch_month</th>\n      <th>launch_day</th>\n      <th>launch_weekday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>drawing for dollars</td>\n      <td>I like drawing pictures. and then i color them...</td>\n      <td>20.0</td>\n      <td>0</td>\n      <td>US</td>\n      <td>USD</td>\n      <td>2009-05-03 02:59:59</td>\n      <td>2009-04-24 15:52:03</td>\n      <td>1</td>\n      <td>8</td>\n      <td>2009</td>\n      <td>4</td>\n      <td>24</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sponsor Dereck Blackburn (Lostwars) Artist in ...</td>\n      <td>I, Dereck Blackburn will be taking upon an inc...</td>\n      <td>300.0</td>\n      <td>0</td>\n      <td>US</td>\n      <td>USD</td>\n      <td>2009-05-15 19:10:00</td>\n      <td>2009-04-28 23:26:32</td>\n      <td>0</td>\n      <td>17</td>\n      <td>2009</td>\n      <td>4</td>\n      <td>28</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Mr. Squiggles</td>\n      <td>So I saw darkpony's successfully funded drawin...</td>\n      <td>30.0</td>\n      <td>0</td>\n      <td>US</td>\n      <td>USD</td>\n      <td>2009-05-22 17:26:00</td>\n      <td>2009-05-12 17:39:58</td>\n      <td>0</td>\n      <td>10</td>\n      <td>2009</td>\n      <td>5</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Help me write my second novel.</td>\n      <td>Do your part to help out starving artists and ...</td>\n      <td>500.0</td>\n      <td>0</td>\n      <td>US</td>\n      <td>USD</td>\n      <td>2009-05-28 20:09:00</td>\n      <td>2009-04-28 20:58:50</td>\n      <td>1</td>\n      <td>30</td>\n      <td>2009</td>\n      <td>4</td>\n      <td>28</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Support casting my sculpture in bronze</td>\n      <td>I'm nearing completion on a sculpture, current...</td>\n      <td>2000.0</td>\n      <td>0</td>\n      <td>US</td>\n      <td>USD</td>\n      <td>2009-05-31 07:38:00</td>\n      <td>2009-05-01 08:22:21</td>\n      <td>0</td>\n      <td>30</td>\n      <td>2009</td>\n      <td>5</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# loading data\n",
    "df = load_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into test and train\n",
    "year = 2015\n",
    "train, test = my_split(df, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting features and target\n",
    "features = ['goal', \n",
    "        'campaign_length', \n",
    "        'launch_month', \n",
    "        'launch_day', \n",
    "        'launch_weekday', \n",
    "        'disable_communication',\n",
    "        'country', \n",
    "        'currency']\n",
    "\n",
    "target = 'final_status'\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n2826/2826 [==============================] - 11s 4ms/step - loss: 0.6488 - accuracy: 0.6550 - get_f1: 0.0692 - val_loss: 0.5915 - val_accuracy: 0.7609 - val_get_f1: 0.0343\nEpoch 2/20\n2826/2826 [==============================] - 9s 3ms/step - loss: 0.6273 - accuracy: 0.6626 - get_f1: 0.0242 - val_loss: 0.5822 - val_accuracy: 0.7602 - val_get_f1: 0.0404\nEpoch 3/20\n2826/2826 [==============================] - 9s 3ms/step - loss: 0.6248 - accuracy: 0.6634 - get_f1: 0.0403 - val_loss: 0.5743 - val_accuracy: 0.7607 - val_get_f1: 0.0315\nEpoch 4/20\n2826/2826 [==============================] - 9s 3ms/step - loss: 0.6228 - accuracy: 0.6637 - get_f1: 0.0475 - val_loss: 0.5818 - val_accuracy: 0.7514 - val_get_f1: 0.0854\nEpoch 5/20\n2826/2826 [==============================] - 9s 3ms/step - loss: 0.6222 - accuracy: 0.6636 - get_f1: 0.0523 - val_loss: 0.5835 - val_accuracy: 0.7463 - val_get_f1: 0.1142\nEpoch 6/20\n2826/2826 [==============================] - 10s 3ms/step - loss: 0.6220 - accuracy: 0.6640 - get_f1: 0.0599 - val_loss: 0.5850 - val_accuracy: 0.7466 - val_get_f1: 0.1124\nEpoch 7/20\n2826/2826 [==============================] - 9s 3ms/step - loss: 0.6219 - accuracy: 0.6636 - get_f1: 0.0608 - val_loss: 0.5748 - val_accuracy: 0.7530 - val_get_f1: 0.0828\nEpoch 8/20\n2826/2826 [==============================] - 7s 3ms/step - loss: 0.6218 - accuracy: 0.6630 - get_f1: 0.0565 - val_loss: 0.5843 - val_accuracy: 0.7473 - val_get_f1: 0.1198\nEpoch 9/20\n2826/2826 [==============================] - 11s 4ms/step - loss: 0.6213 - accuracy: 0.6640 - get_f1: 0.0637 - val_loss: 0.5752 - val_accuracy: 0.7508 - val_get_f1: 0.0981\nEpoch 10/20\n2826/2826 [==============================] - 7s 3ms/step - loss: 0.6213 - accuracy: 0.6641 - get_f1: 0.0623 - val_loss: 0.5857 - val_accuracy: 0.7341 - val_get_f1: 0.1420\nEpoch 11/20\n2826/2826 [==============================] - 13s 5ms/step - loss: 0.6211 - accuracy: 0.6635 - get_f1: 0.0679 - val_loss: 0.5689 - val_accuracy: 0.7545 - val_get_f1: 0.0714\nEpoch 12/20\n2826/2826 [==============================] - 12s 4ms/step - loss: 0.6213 - accuracy: 0.6636 - get_f1: 0.0667 - val_loss: 0.5768 - val_accuracy: 0.7432 - val_get_f1: 0.1085\nEpoch 13/20\n2826/2826 [==============================] - 14s 5ms/step - loss: 0.6211 - accuracy: 0.6639 - get_f1: 0.0707 - val_loss: 0.5660 - val_accuracy: 0.7571 - val_get_f1: 0.0616\nEpoch 14/20\n2826/2826 [==============================] - 12s 4ms/step - loss: 0.6211 - accuracy: 0.6634 - get_f1: 0.0671 - val_loss: 0.5704 - val_accuracy: 0.7546 - val_get_f1: 0.0681\nEpoch 15/20\n2826/2826 [==============================] - 12s 4ms/step - loss: 0.6211 - accuracy: 0.6634 - get_f1: 0.0679 - val_loss: 0.5627 - val_accuracy: 0.7541 - val_get_f1: 0.0791\nEpoch 16/20\n2826/2826 [==============================] - 12s 4ms/step - loss: 0.6208 - accuracy: 0.6638 - get_f1: 0.0697 - val_loss: 0.5653 - val_accuracy: 0.7567 - val_get_f1: 0.0652\nEpoch 17/20\n2826/2826 [==============================] - 12s 4ms/step - loss: 0.6205 - accuracy: 0.6644 - get_f1: 0.0731 - val_loss: 0.5793 - val_accuracy: 0.7382 - val_get_f1: 0.1479\nEpoch 18/20\n2826/2826 [==============================] - 11s 4ms/step - loss: 0.6208 - accuracy: 0.6635 - get_f1: 0.0724 - val_loss: 0.5635 - val_accuracy: 0.7568 - val_get_f1: 0.0639\nEpoch 19/20\n2826/2826 [==============================] - 11s 4ms/step - loss: 0.6203 - accuracy: 0.6636 - get_f1: 0.0713 - val_loss: 0.5631 - val_accuracy: 0.7575 - val_get_f1: 0.0678\nEpoch 20/20\n2826/2826 [==============================] - 12s 4ms/step - loss: 0.6195 - accuracy: 0.6648 - get_f1: 0.0746 - val_loss: 0.5822 - val_accuracy: 0.7238 - val_get_f1: 0.1629\n-------------------------------\nAccuracy Score: 0.723826714801444\nROC AUC Score: 0.5309832634963456\nF1 Score: 0.22408874801901743\n"
    }
   ],
   "source": [
    "# basic neural network - no change to class balance\n",
    "X_train, y_train, X_test, y_test = model_prep(train, test, features, target)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', get_f1]\n",
    ")\n",
    "\n",
    "history = model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test) \n",
    "          )\n",
    "\n",
    "# scores with no change\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "y_true = y_test\n",
    "\n",
    "get_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n1905/1905 [==============================] - 5s 2ms/step - loss: 0.6908 - accuracy: 0.5423 - get_f1: 0.5814 - val_loss: 0.7210 - val_accuracy: 0.4191 - val_get_f1: 0.3685\nEpoch 2/20\n1905/1905 [==============================] - 4s 2ms/step - loss: 0.6804 - accuracy: 0.5561 - get_f1: 0.5894 - val_loss: 0.7253 - val_accuracy: 0.4057 - val_get_f1: 0.3820\nEpoch 3/20\n1905/1905 [==============================] - 5s 3ms/step - loss: 0.6773 - accuracy: 0.5651 - get_f1: 0.5837 - val_loss: 0.7408 - val_accuracy: 0.4059 - val_get_f1: 0.3854\nEpoch 4/20\n1905/1905 [==============================] - 4s 2ms/step - loss: 0.6763 - accuracy: 0.5672 - get_f1: 0.5829 - val_loss: 0.7361 - val_accuracy: 0.4030 - val_get_f1: 0.3861\nEpoch 5/20\n1905/1905 [==============================] - 4s 2ms/step - loss: 0.6751 - accuracy: 0.5724 - get_f1: 0.5843 - val_loss: 0.7302 - val_accuracy: 0.4151 - val_get_f1: 0.3879\nEpoch 6/20\n1905/1905 [==============================] - 4s 2ms/step - loss: 0.6744 - accuracy: 0.5749 - get_f1: 0.5877 - val_loss: 0.7428 - val_accuracy: 0.3884 - val_get_f1: 0.3849\nEpoch 7/20\n1905/1905 [==============================] - 4s 2ms/step - loss: 0.6739 - accuracy: 0.5762 - get_f1: 0.5920 - val_loss: 0.7162 - val_accuracy: 0.4387 - val_get_f1: 0.3887\nEpoch 8/20\n1905/1905 [==============================] - 4s 2ms/step - loss: 0.6737 - accuracy: 0.5775 - get_f1: 0.5890 - val_loss: 0.7100 - val_accuracy: 0.4537 - val_get_f1: 0.3836\nEpoch 9/20\n1905/1905 [==============================] - 4s 2ms/step - loss: 0.6735 - accuracy: 0.5780 - get_f1: 0.5954 - val_loss: 0.7413 - val_accuracy: 0.4119 - val_get_f1: 0.3913\nEpoch 10/20\n1905/1905 [==============================] - 4s 2ms/step - loss: 0.6735 - accuracy: 0.5769 - get_f1: 0.5915 - val_loss: 0.7494 - val_accuracy: 0.4024 - val_get_f1: 0.3891\nEpoch 11/20\n1905/1905 [==============================] - 4s 2ms/step - loss: 0.6725 - accuracy: 0.5789 - get_f1: 0.5942 - val_loss: 0.7298 - val_accuracy: 0.4191 - val_get_f1: 0.3947\nEpoch 12/20\n1905/1905 [==============================] - 4s 2ms/step - loss: 0.6725 - accuracy: 0.5814 - get_f1: 0.6021 - val_loss: 0.7283 - val_accuracy: 0.4279 - val_get_f1: 0.3907\nEpoch 13/20\n1905/1905 [==============================] - 4s 2ms/step - loss: 0.6726 - accuracy: 0.5784 - get_f1: 0.5942 - val_loss: 0.7201 - val_accuracy: 0.4374 - val_get_f1: 0.3846\nEpoch 14/20\n1905/1905 [==============================] - 4s 2ms/step - loss: 0.6720 - accuracy: 0.5803 - get_f1: 0.5952 - val_loss: 0.7047 - val_accuracy: 0.4734 - val_get_f1: 0.3870\nEpoch 15/20\n1905/1905 [==============================] - 4s 2ms/step - loss: 0.6721 - accuracy: 0.5799 - get_f1: 0.5926 - val_loss: 0.7057 - val_accuracy: 0.4686 - val_get_f1: 0.3844\nEpoch 16/20\n1905/1905 [==============================] - 4s 2ms/step - loss: 0.6710 - accuracy: 0.5830 - get_f1: 0.5994 - val_loss: 0.7091 - val_accuracy: 0.4738 - val_get_f1: 0.3885\nEpoch 17/20\n1905/1905 [==============================] - 4s 2ms/step - loss: 0.6702 - accuracy: 0.5828 - get_f1: 0.6005 - val_loss: 0.7142 - val_accuracy: 0.4474 - val_get_f1: 0.3930\nEpoch 18/20\n1905/1905 [==============================] - 4s 2ms/step - loss: 0.6708 - accuracy: 0.5829 - get_f1: 0.5962 - val_loss: 0.7051 - val_accuracy: 0.4657 - val_get_f1: 0.3873\nEpoch 19/20\n1905/1905 [==============================] - 4s 2ms/step - loss: 0.6707 - accuracy: 0.5840 - get_f1: 0.5930 - val_loss: 0.7311 - val_accuracy: 0.4361 - val_get_f1: 0.3923\nEpoch 20/20\n1905/1905 [==============================] - 4s 2ms/step - loss: 0.6705 - accuracy: 0.5841 - get_f1: 0.5961 - val_loss: 0.7270 - val_accuracy: 0.4472 - val_get_f1: 0.3893\n-------------------------------\nAccuracy Score: 0.447202166064982\nROC AUC Score: 0.5706145712272757\nF1 Score: 0.4004649455524287\n"
    }
   ],
   "source": [
    "# basic neural network - downsampling minority class\n",
    "train_downsampled = downsample_majority(train)\n",
    "\n",
    "X_train, y_train, X_test, y_test = model_prep(train_downsampled, test, features, target)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', get_f1]\n",
    ")\n",
    "\n",
    "history = model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test) \n",
    "          )\n",
    "\n",
    "# scores with upsampling\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "y_true = y_test\n",
    "\n",
    "get_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n1905/1905 [==============================] - 7s 3ms/step - loss: 0.6944 - accuracy: 0.5494 - get_f1: 0.5791 - val_loss: 0.7307 - val_accuracy: 0.3903 - val_get_f1: 0.3795\nEpoch 2/20\n1905/1905 [==============================] - 6s 3ms/step - loss: 0.6802 - accuracy: 0.5620 - get_f1: 0.5946 - val_loss: 0.7328 - val_accuracy: 0.4019 - val_get_f1: 0.3806\nEpoch 3/20\n1905/1905 [==============================] - 6s 3ms/step - loss: 0.6778 - accuracy: 0.5658 - get_f1: 0.5933 - val_loss: 0.7419 - val_accuracy: 0.4155 - val_get_f1: 0.3788\nEpoch 4/20\n1905/1905 [==============================] - 5s 3ms/step - loss: 0.6761 - accuracy: 0.5698 - get_f1: 0.5930 - val_loss: 0.7190 - val_accuracy: 0.4320 - val_get_f1: 0.3862\nEpoch 5/20\n1905/1905 [==============================] - 6s 3ms/step - loss: 0.6745 - accuracy: 0.5758 - get_f1: 0.5955 - val_loss: 0.7152 - val_accuracy: 0.4464 - val_get_f1: 0.3865\nEpoch 6/20\n1905/1905 [==============================] - 5s 3ms/step - loss: 0.6735 - accuracy: 0.5762 - get_f1: 0.5916 - val_loss: 0.7227 - val_accuracy: 0.4288 - val_get_f1: 0.3932\nEpoch 7/20\n1905/1905 [==============================] - 6s 3ms/step - loss: 0.6728 - accuracy: 0.5784 - get_f1: 0.5939 - val_loss: 0.7136 - val_accuracy: 0.4501 - val_get_f1: 0.3914\nEpoch 8/20\n1905/1905 [==============================] - 6s 3ms/step - loss: 0.6729 - accuracy: 0.5775 - get_f1: 0.5895 - val_loss: 0.7183 - val_accuracy: 0.4414 - val_get_f1: 0.3910\nEpoch 9/20\n1905/1905 [==============================] - 6s 3ms/step - loss: 0.6721 - accuracy: 0.5791 - get_f1: 0.5945 - val_loss: 0.7260 - val_accuracy: 0.4410 - val_get_f1: 0.3901\nEpoch 10/20\n1905/1905 [==============================] - 9s 5ms/step - loss: 0.6713 - accuracy: 0.5803 - get_f1: 0.5954 - val_loss: 0.7064 - val_accuracy: 0.4668 - val_get_f1: 0.3901\nEpoch 11/20\n1905/1905 [==============================] - 14s 7ms/step - loss: 0.6716 - accuracy: 0.5804 - get_f1: 0.5916 - val_loss: 0.7190 - val_accuracy: 0.4444 - val_get_f1: 0.3947\nEpoch 12/20\n1905/1905 [==============================] - 7s 4ms/step - loss: 0.6716 - accuracy: 0.5818 - get_f1: 0.5967 - val_loss: 0.7206 - val_accuracy: 0.4642 - val_get_f1: 0.3863\nEpoch 13/20\n1905/1905 [==============================] - 7s 4ms/step - loss: 0.6706 - accuracy: 0.5843 - get_f1: 0.5985 - val_loss: 0.7286 - val_accuracy: 0.4488 - val_get_f1: 0.3906\nEpoch 14/20\n1905/1905 [==============================] - 7s 4ms/step - loss: 0.6705 - accuracy: 0.5824 - get_f1: 0.5971 - val_loss: 0.7182 - val_accuracy: 0.4649 - val_get_f1: 0.3893\nEpoch 15/20\n1905/1905 [==============================] - 7s 4ms/step - loss: 0.6703 - accuracy: 0.5841 - get_f1: 0.5944 - val_loss: 0.7074 - val_accuracy: 0.4797 - val_get_f1: 0.3924\nEpoch 16/20\n1905/1905 [==============================] - 8s 4ms/step - loss: 0.6703 - accuracy: 0.5848 - get_f1: 0.5943 - val_loss: 0.6928 - val_accuracy: 0.5005 - val_get_f1: 0.3836\nEpoch 17/20\n1905/1905 [==============================] - 9s 5ms/step - loss: 0.6699 - accuracy: 0.5849 - get_f1: 0.5943 - val_loss: 0.7234 - val_accuracy: 0.4494 - val_get_f1: 0.3946\nEpoch 18/20\n1905/1905 [==============================] - 8s 4ms/step - loss: 0.6696 - accuracy: 0.5859 - get_f1: 0.5943 - val_loss: 0.7345 - val_accuracy: 0.4403 - val_get_f1: 0.3924\nEpoch 19/20\n1905/1905 [==============================] - 8s 4ms/step - loss: 0.6695 - accuracy: 0.5853 - get_f1: 0.5941 - val_loss: 0.7053 - val_accuracy: 0.4768 - val_get_f1: 0.3901\nEpoch 20/20\n1905/1905 [==============================] - 7s 4ms/step - loss: 0.6698 - accuracy: 0.5843 - get_f1: 0.5882 - val_loss: 0.7240 - val_accuracy: 0.4566 - val_get_f1: 0.3880\n-------------------------------\nAccuracy Score: 0.4565658844765343\nROC AUC Score: 0.5707148606400113\nF1 Score: 0.39937655860349136\n"
    }
   ],
   "source": [
    "# basic neural network - downsampling majority class\n",
    "train_downsampled = downsample_majority(train)\n",
    "X_train, y_train, X_test, y_test = model_prep(train_downsampled, test, features, target)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', get_f1]\n",
    ")\n",
    "\n",
    "history = model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test) \n",
    "          )\n",
    "\n",
    "# scores with downsampling\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "y_true = y_test\n",
    "\n",
    "get_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n1905/1905 [==============================] - 10s 5ms/step - loss: 0.6878 - accuracy: 0.5434 - get_f1: 0.5582 - val_loss: 0.6948 - val_accuracy: 0.4720 - val_get_f1: 0.3654\nEpoch 2/20\n1905/1905 [==============================] - 10s 5ms/step - loss: 0.6827 - accuracy: 0.5550 - get_f1: 0.5562 - val_loss: 0.7184 - val_accuracy: 0.4205 - val_get_f1: 0.3736\nEpoch 3/20\n1905/1905 [==============================] - 10s 5ms/step - loss: 0.6808 - accuracy: 0.5599 - get_f1: 0.5473 - val_loss: 0.7180 - val_accuracy: 0.4165 - val_get_f1: 0.3850\nEpoch 4/20\n1905/1905 [==============================] - 9s 5ms/step - loss: 0.6788 - accuracy: 0.5643 - get_f1: 0.5578 - val_loss: 0.7089 - val_accuracy: 0.4296 - val_get_f1: 0.3859\nEpoch 5/20\n1905/1905 [==============================] - 10s 5ms/step - loss: 0.6767 - accuracy: 0.5706 - get_f1: 0.5630 - val_loss: 0.6972 - val_accuracy: 0.4978 - val_get_f1: 0.3730\nEpoch 6/20\n1905/1905 [==============================] - 13s 7ms/step - loss: 0.6745 - accuracy: 0.5767 - get_f1: 0.5690 - val_loss: 0.7106 - val_accuracy: 0.4681 - val_get_f1: 0.3775\nEpoch 7/20\n1905/1905 [==============================] - 13s 7ms/step - loss: 0.6737 - accuracy: 0.5788 - get_f1: 0.5893 - val_loss: 0.7243 - val_accuracy: 0.4640 - val_get_f1: 0.3883\nEpoch 8/20\n1905/1905 [==============================] - 13s 7ms/step - loss: 0.6720 - accuracy: 0.5829 - get_f1: 0.5934 - val_loss: 0.7301 - val_accuracy: 0.4585 - val_get_f1: 0.3905\nEpoch 9/20\n1905/1905 [==============================] - 11s 6ms/step - loss: 0.6713 - accuracy: 0.5864 - get_f1: 0.5990 - val_loss: 0.7127 - val_accuracy: 0.4637 - val_get_f1: 0.3907\nEpoch 10/20\n1905/1905 [==============================] - 12s 6ms/step - loss: 0.6717 - accuracy: 0.5831 - get_f1: 0.5955 - val_loss: 0.7197 - val_accuracy: 0.4673 - val_get_f1: 0.3896\nEpoch 11/20\n1905/1905 [==============================] - 13s 7ms/step - loss: 0.6710 - accuracy: 0.5849 - get_f1: 0.5933 - val_loss: 0.7069 - val_accuracy: 0.4805 - val_get_f1: 0.3916\nEpoch 12/20\n1905/1905 [==============================] - 11s 6ms/step - loss: 0.6705 - accuracy: 0.5865 - get_f1: 0.5934 - val_loss: 0.7251 - val_accuracy: 0.4675 - val_get_f1: 0.3910\nEpoch 13/20\n1905/1905 [==============================] - 11s 6ms/step - loss: 0.6708 - accuracy: 0.5862 - get_f1: 0.5946 - val_loss: 0.7154 - val_accuracy: 0.4570 - val_get_f1: 0.3914\nEpoch 14/20\n1905/1905 [==============================] - 13s 7ms/step - loss: 0.6700 - accuracy: 0.5864 - get_f1: 0.6011 - val_loss: 0.7209 - val_accuracy: 0.4535 - val_get_f1: 0.3896\nEpoch 15/20\n1905/1905 [==============================] - 31s 16ms/step - loss: 0.6696 - accuracy: 0.5886 - get_f1: 0.5949 - val_loss: 0.7083 - val_accuracy: 0.4595 - val_get_f1: 0.3884\nEpoch 16/20\n1905/1905 [==============================] - 31s 16ms/step - loss: 0.6700 - accuracy: 0.5874 - get_f1: 0.5971 - val_loss: 0.6924 - val_accuracy: 0.5060 - val_get_f1: 0.3896\nEpoch 17/20\n1905/1905 [==============================] - 22s 11ms/step - loss: 0.6703 - accuracy: 0.5867 - get_f1: 0.5981 - val_loss: 0.7061 - val_accuracy: 0.4737 - val_get_f1: 0.3914\nEpoch 18/20\n1905/1905 [==============================] - 19s 10ms/step - loss: 0.6685 - accuracy: 0.5884 - get_f1: 0.5968 - val_loss: 0.7206 - val_accuracy: 0.4593 - val_get_f1: 0.3971\nEpoch 19/20\n1905/1905 [==============================] - 17s 9ms/step - loss: 0.6691 - accuracy: 0.5874 - get_f1: 0.5948 - val_loss: 0.7028 - val_accuracy: 0.4970 - val_get_f1: 0.3897\nEpoch 20/20\n1905/1905 [==============================] - 19s 10ms/step - loss: 0.6688 - accuracy: 0.5874 - get_f1: 0.5979 - val_loss: 0.7030 - val_accuracy: 0.5073 - val_get_f1: 0.3832\n-------------------------------\nAccuracy Score: 0.5073330324909747\nROC AUC Score: 0.5762631806382221\nF1 Score: 0.39757207890743557\n"
    }
   ],
   "source": [
    "# adding layers - downsampling majority class\n",
    "train_downsampled = downsample_majority(train)\n",
    "\n",
    "X_train, y_train, X_test, y_test = model_prep(train_downsampled, test, features, target)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', get_f1]\n",
    ")\n",
    "\n",
    "# fitting the model\n",
    "history = model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test) \n",
    "          )\n",
    "\n",
    "# scores\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "y_true = y_test\n",
    "\n",
    "get_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n1905/1905 [==============================] - 51s 27ms/step - loss: 0.6846 - accuracy: 0.5539 - get_f1: 0.5439 - val_loss: 0.7139 - val_accuracy: 0.4464 - val_get_f1: 0.3681\nEpoch 2/20\n1905/1905 [==============================] - 36s 19ms/step - loss: 0.6788 - accuracy: 0.5696 - get_f1: 0.5611 - val_loss: 0.7199 - val_accuracy: 0.4698 - val_get_f1: 0.3730\nEpoch 3/20\n1905/1905 [==============================] - 24s 12ms/step - loss: 0.6764 - accuracy: 0.5740 - get_f1: 0.5704 - val_loss: 0.7278 - val_accuracy: 0.4607 - val_get_f1: 0.3757\nEpoch 4/20\n1905/1905 [==============================] - 24s 13ms/step - loss: 0.6745 - accuracy: 0.5779 - get_f1: 0.5672 - val_loss: 0.7304 - val_accuracy: 0.4421 - val_get_f1: 0.3877\nEpoch 5/20\n1905/1905 [==============================] - 24s 13ms/step - loss: 0.6731 - accuracy: 0.5816 - get_f1: 0.5875 - val_loss: 0.7041 - val_accuracy: 0.4591 - val_get_f1: 0.3912\nEpoch 6/20\n1905/1905 [==============================] - 24s 13ms/step - loss: 0.6719 - accuracy: 0.5846 - get_f1: 0.5930 - val_loss: 0.7369 - val_accuracy: 0.4475 - val_get_f1: 0.3855\nEpoch 7/20\n1905/1905 [==============================] - 17s 9ms/step - loss: 0.6707 - accuracy: 0.5833 - get_f1: 0.5879 - val_loss: 0.6924 - val_accuracy: 0.4972 - val_get_f1: 0.3895\nEpoch 8/20\n1905/1905 [==============================] - 16s 9ms/step - loss: 0.6698 - accuracy: 0.5861 - get_f1: 0.5965 - val_loss: 0.7424 - val_accuracy: 0.4396 - val_get_f1: 0.3897\nEpoch 9/20\n1905/1905 [==============================] - 22s 12ms/step - loss: 0.6698 - accuracy: 0.5857 - get_f1: 0.5918 - val_loss: 0.7561 - val_accuracy: 0.4310 - val_get_f1: 0.3929\nEpoch 10/20\n1905/1905 [==============================] - 21s 11ms/step - loss: 0.6698 - accuracy: 0.5877 - get_f1: 0.5972 - val_loss: 0.7003 - val_accuracy: 0.4681 - val_get_f1: 0.3917\nEpoch 11/20\n1905/1905 [==============================] - 34s 18ms/step - loss: 0.6692 - accuracy: 0.5879 - get_f1: 0.5957 - val_loss: 0.6886 - val_accuracy: 0.5008 - val_get_f1: 0.3879\nEpoch 12/20\n1905/1905 [==============================] - 30s 16ms/step - loss: 0.6691 - accuracy: 0.5874 - get_f1: 0.5874 - val_loss: 0.7241 - val_accuracy: 0.4590 - val_get_f1: 0.3805\nEpoch 13/20\n1905/1905 [==============================] - 17s 9ms/step - loss: 0.6684 - accuracy: 0.5895 - get_f1: 0.5932 - val_loss: 0.7168 - val_accuracy: 0.4688 - val_get_f1: 0.3895\nEpoch 14/20\n1905/1905 [==============================] - 16s 8ms/step - loss: 0.6675 - accuracy: 0.5907 - get_f1: 0.5960 - val_loss: 0.7135 - val_accuracy: 0.4968 - val_get_f1: 0.3881\nEpoch 15/20\n1905/1905 [==============================] - 14s 7ms/step - loss: 0.6677 - accuracy: 0.5899 - get_f1: 0.6020 - val_loss: 0.6734 - val_accuracy: 0.5140 - val_get_f1: 0.3841\nEpoch 16/20\n1905/1905 [==============================] - 14s 7ms/step - loss: 0.6679 - accuracy: 0.5908 - get_f1: 0.5996 - val_loss: 0.6950 - val_accuracy: 0.4858 - val_get_f1: 0.3848\nEpoch 17/20\n1905/1905 [==============================] - 14s 7ms/step - loss: 0.6674 - accuracy: 0.5909 - get_f1: 0.6042 - val_loss: 0.6966 - val_accuracy: 0.4610 - val_get_f1: 0.3872\nEpoch 18/20\n1905/1905 [==============================] - 14s 7ms/step - loss: 0.6675 - accuracy: 0.5898 - get_f1: 0.6014 - val_loss: 0.6807 - val_accuracy: 0.5165 - val_get_f1: 0.3822\nEpoch 19/20\n1905/1905 [==============================] - 13s 7ms/step - loss: 0.6670 - accuracy: 0.5915 - get_f1: 0.6006 - val_loss: 0.6904 - val_accuracy: 0.4791 - val_get_f1: 0.3932\nEpoch 20/20\n1905/1905 [==============================] - 13s 7ms/step - loss: 0.6668 - accuracy: 0.5927 - get_f1: 0.6027 - val_loss: 0.7189 - val_accuracy: 0.4552 - val_get_f1: 0.3926\n-------------------------------\nAccuracy Score: 0.4551556859205776\nROC AUC Score: 0.5760412750791634\nF1 Score: 0.4041700080192462\n"
    }
   ],
   "source": [
    "# adding layers, massive amount of neurons - downsampling majority class\n",
    "train_downsampled = downsample_majority(train)\n",
    "\n",
    "X_train, y_train, X_test, y_test = model_prep(train_downsampled, test, features, target)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', get_f1]\n",
    ")\n",
    "\n",
    "# fitting the model\n",
    "history = model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test) \n",
    "          )\n",
    "\n",
    "# scores\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "y_true = y_test\n",
    "\n",
    "get_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n1905/1905 [==============================] - 43s 22ms/step - loss: 0.6832 - accuracy: 0.5587 - get_f1: 0.5592 - val_loss: 0.7247 - val_accuracy: 0.4274 - val_get_f1: 0.3665\nEpoch 2/20\n1905/1905 [==============================] - 42s 22ms/step - loss: 0.6772 - accuracy: 0.5728 - get_f1: 0.5757 - val_loss: 0.8123 - val_accuracy: 0.3982 - val_get_f1: 0.3861\nEpoch 3/20\n1905/1905 [==============================] - 47s 25ms/step - loss: 0.6747 - accuracy: 0.5761 - get_f1: 0.5748 - val_loss: 0.7350 - val_accuracy: 0.4726 - val_get_f1: 0.3705\nEpoch 4/20\n1905/1905 [==============================] - 43s 23ms/step - loss: 0.6738 - accuracy: 0.5797 - get_f1: 0.5920 - val_loss: 0.7336 - val_accuracy: 0.4725 - val_get_f1: 0.3727\nEpoch 5/20\n1905/1905 [==============================] - 43s 22ms/step - loss: 0.6723 - accuracy: 0.5819 - get_f1: 0.5904 - val_loss: 0.7481 - val_accuracy: 0.4266 - val_get_f1: 0.3899\nEpoch 6/20\n1905/1905 [==============================] - 48s 25ms/step - loss: 0.6703 - accuracy: 0.5838 - get_f1: 0.6016 - val_loss: 0.6893 - val_accuracy: 0.4891 - val_get_f1: 0.3747\nEpoch 7/20\n1905/1905 [==============================] - 48s 25ms/step - loss: 0.6702 - accuracy: 0.5856 - get_f1: 0.6027 - val_loss: 0.7123 - val_accuracy: 0.4782 - val_get_f1: 0.3823\nEpoch 8/20\n1905/1905 [==============================] - 45s 24ms/step - loss: 0.6700 - accuracy: 0.5877 - get_f1: 0.5966 - val_loss: 0.7197 - val_accuracy: 0.4730 - val_get_f1: 0.3898\nEpoch 9/20\n1905/1905 [==============================] - 44s 23ms/step - loss: 0.6695 - accuracy: 0.5852 - get_f1: 0.5997 - val_loss: 0.7521 - val_accuracy: 0.5030 - val_get_f1: 0.3794\nEpoch 10/20\n1905/1905 [==============================] - 46s 24ms/step - loss: 0.6689 - accuracy: 0.5879 - get_f1: 0.6045 - val_loss: 0.7354 - val_accuracy: 0.4498 - val_get_f1: 0.3831\nEpoch 11/20\n1905/1905 [==============================] - 46s 24ms/step - loss: 0.6685 - accuracy: 0.5899 - get_f1: 0.6010 - val_loss: 0.7271 - val_accuracy: 0.4862 - val_get_f1: 0.3904\nEpoch 12/20\n1905/1905 [==============================] - 42s 22ms/step - loss: 0.6681 - accuracy: 0.5882 - get_f1: 0.5991 - val_loss: 0.7035 - val_accuracy: 0.4471 - val_get_f1: 0.3898\nEpoch 13/20\n1905/1905 [==============================] - 41s 22ms/step - loss: 0.6683 - accuracy: 0.5869 - get_f1: 0.5936 - val_loss: 0.6929 - val_accuracy: 0.4903 - val_get_f1: 0.3891\nEpoch 14/20\n1905/1905 [==============================] - 44s 23ms/step - loss: 0.6681 - accuracy: 0.5892 - get_f1: 0.5890 - val_loss: 0.7047 - val_accuracy: 0.4937 - val_get_f1: 0.3905\nEpoch 15/20\n1905/1905 [==============================] - 45s 23ms/step - loss: 0.6677 - accuracy: 0.5903 - get_f1: 0.5956 - val_loss: 0.7312 - val_accuracy: 0.4566 - val_get_f1: 0.3921\nEpoch 16/20\n1905/1905 [==============================] - 44s 23ms/step - loss: 0.6667 - accuracy: 0.5898 - get_f1: 0.5950 - val_loss: 0.7159 - val_accuracy: 0.4806 - val_get_f1: 0.3707\nEpoch 17/20\n1905/1905 [==============================] - 45s 24ms/step - loss: 0.6669 - accuracy: 0.5910 - get_f1: 0.5986 - val_loss: 0.7189 - val_accuracy: 0.4737 - val_get_f1: 0.3933\nEpoch 18/20\n1905/1905 [==============================] - 45s 24ms/step - loss: 0.6669 - accuracy: 0.5894 - get_f1: 0.6000 - val_loss: 0.7152 - val_accuracy: 0.4935 - val_get_f1: 0.3861\nEpoch 19/20\n1905/1905 [==============================] - 45s 24ms/step - loss: 0.6666 - accuracy: 0.5900 - get_f1: 0.5988 - val_loss: 0.7358 - val_accuracy: 0.4956 - val_get_f1: 0.3895\nEpoch 20/20\n1905/1905 [==============================] - 47s 25ms/step - loss: 0.6666 - accuracy: 0.5901 - get_f1: 0.5972 - val_loss: 0.7272 - val_accuracy: 0.4835 - val_get_f1: 0.3918\n-------------------------------\nAccuracy Score: 0.4834724729241877\nROC AUC Score: 0.5802517816245709\nF1 Score: 0.4045002276126683\n"
    }
   ],
   "source": [
    "# adding layers, massive amount of neurons - downsampling majority class\n",
    "train_downsampled = downsample_majority(train)\n",
    "\n",
    "X_train, y_train, X_test, y_test = model_prep(train_downsampled, test, features, target)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(300,  activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(300,  activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(300,  activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', get_f1]\n",
    ")\n",
    "\n",
    "# fitting the model\n",
    "history = model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test) \n",
    "          )\n",
    "\n",
    "# scores\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "y_true = y_test\n",
    "\n",
    "get_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grid search, this will return accuracy but that should hopefully also equal a higher f1\n",
    "# when trained on a balanced set\n",
    "train_downsampled = downsample_majority(train)\n",
    "X_train, y_train, X_test, y_test = model_prep(train_downsampled, test, features, target)\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "def create_model(lr, optimizer='adam', number_layers=1,\n",
    "        neurons1=1, act1='relu', init_mode1='uniform', dropout_rate1=0.0,\n",
    "        neurons2=1, act2='relu', init_mode2='uniform', dropout_rate2=0.0,\n",
    "        neurons3=1, act3='relu', init_mode3='uniform', dropout_rate3=0.0,\n",
    "        neurons4=1, act4='relu', init_mode4='uniform', dropout_rate4=0.0,\n",
    "        neurons5=1, act5='relu', init_mode5='uniform', dropout_rate5=0.0,\n",
    "        init_mode6='uniform'):\n",
    "    adam = Adam(learning_rate=lr)\n",
    "    model = Sequential()\n",
    "    if number_layers <= 1:\n",
    "        model.add(Dense(neurons1, activation=act1, kernel_initializer=init_mode1, input_shape=(input_dim,)))\n",
    "        model.add(Dropout(dropout_rate1))\n",
    "\n",
    "    if number_layers <= 2:\n",
    "        model.add(Dense(neurons2, activation=act2, kernel_initializer=init_mode2))\n",
    "        model.add(Dropout(dropout_rate2))\n",
    "\n",
    "    if number_layers <= 3:\n",
    "        model.add(Dense(neurons3, activation=act3, kernel_initializer=init_mode3))\n",
    "        model.add(Dropout(dropout_rate3))\n",
    "\n",
    "    if number_layers <= 4:\n",
    "        model.add(Dense(neurons4, activation=act4, kernel_initializer=init_mode4))\n",
    "        model.add(Dropout(dropout_rate4))\n",
    "\n",
    "    if number_layers <= 5:\n",
    "        model.add(Dense(neurons5, activation=act5, kernel_initializer=init_mode5))\n",
    "        model.add(Dropout(dropout_rate5))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=init_mode6))\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=10)\n",
    "\n",
    "\n",
    "param_grid = {'batch_size': [50, 100],\n",
    "            'epochs': [20],\n",
    "            'lr': [.01, .1, .5], \n",
    "            'optimizer': ['adam'], \n",
    "            'number_layers': [1, 2, 3], \n",
    "            'neurons1': [1, 5, 10, 20], \n",
    "            'act1': ['relu'], \n",
    "            'init_mode1': ['uniform'], \n",
    "            'dropout_rate1': [0, .1, .3],   \n",
    "            'neurons2': [1, 5, 10, 20], \n",
    "            'act2': ['relu'], \n",
    "            'init_mode2': ['uniform'], \n",
    "            'dropout_rate2': [0, .1, .3],   \n",
    "            'neurons3': [1, 5, 10, 20], \n",
    "            'act3': ['relu'], \n",
    "            'init_mode3': ['uniform'], \n",
    "            'dropout_rate3': [0, .1, .3],\n",
    "            #'neurons4': [1, 5, 10, 20],   # commenting these out to reduce run time\n",
    "            #'act4': ['relu'], \n",
    "            #'init_mode4': ['uniform'], \n",
    "            #'dropout_rate4': [0, .1, .3],\n",
    "            #'neurons5': [1, 5, 10, 20], \n",
    "            #'act5': ['relu'], \n",
    "            #'init_mode5': ['uniform'], \n",
    "            #'dropout_rate5': [0, .1, .3],\n",
    "            'init_mode6': ['uniform']}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=4)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}