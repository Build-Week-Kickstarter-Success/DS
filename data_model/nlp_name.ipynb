{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Copy of nlp_name.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q31XCKTbRSkJ",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAANoPXNQUTT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "639a1788-3ea4-40f5-c109-4441ee296367"
      },
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "import numpy as np\n",
        "import pickle\n",
        "import keras\n",
        "from tensorflow.keras.constraints import unit_norm\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "'''\n",
        "from helper_functions import load_data\n",
        "from helper_functions import my_split\n",
        "from helper_functions import upsample_minority\n",
        "from helper_functions import downsample_majority\n",
        "from helper_functions import model_prep\n",
        "from helper_functions import get_results\n",
        "from helper_functions import get_f1\n",
        "from helper_functions import clean_text\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom helper_functions import load_data\\nfrom helper_functions import my_split\\nfrom helper_functions import upsample_minority\\nfrom helper_functions import downsample_majority\\nfrom helper_functions import model_prep\\nfrom helper_functions import get_results\\nfrom helper_functions import get_f1\\nfrom helper_functions import clean_text\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Np6tZxQrpV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "35558604-38f1-4768-a528-f261cb49e42e"
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 18.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.0.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGgFSBRYQaLe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "38385dee-c77f-4535-8b11-d63e1edd2f45"
      },
      "source": [
        "# imports\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.utils import resample\n",
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "import keras.backend as K\n",
        "import re\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    FILE_PATH = os.path.join(os.getcwd(), 'data', 'large_data.csv')\n",
        "    return pd.read_csv(FILE_PATH, index_col=None)\n",
        "\n",
        "def upsample_minority(df):\n",
        "    counts = df['final_status'].value_counts().index\n",
        "    majority = counts[0]\n",
        "    minority = counts[1]\n",
        "\n",
        "    df_majority = df[df['final_status'] == majority]\n",
        "    df_minority = df[df['final_status'] == minority]\n",
        "\n",
        "    majority_class_size = len(df_majority)\n",
        "    minority_class_size = len(df_minority)\n",
        "\n",
        "    minority_upsampled = resample(df_minority, \n",
        "                replace=True, \n",
        "                n_samples=majority_class_size,\n",
        "                random_state=42) \n",
        "    return pd.concat([df_majority, minority_upsampled])\n",
        "\n",
        "def downsample_majority(df):\n",
        "    counts = df['final_status'].value_counts().index\n",
        "    majority = counts[0]\n",
        "    minority = counts[1]\n",
        "\n",
        "    df_majority = df[df['final_status'] == majority]\n",
        "    df_minority = df[df['final_status'] == minority]\n",
        "\n",
        "    majority_class_size = len(df_majority)\n",
        "    minority_class_size = len(df_minority)\n",
        "\n",
        "    majority_downsampled = resample(df_majority, \n",
        "                replace=False, \n",
        "                n_samples=minority_class_size,\n",
        "                random_state=42) \n",
        "    return pd.concat([df_minority, majority_downsampled])\n",
        "\n",
        "def my_split(df, year):\n",
        "    train = df[df['launch_year'] < year]\n",
        "    test = df[df['launch_year'] == year]\n",
        "    return train, test\n",
        "\n",
        "def model_prep(train, test, features, target, onehot=True, scale=True):\n",
        "    encoder = ce.one_hot.OneHotEncoder(use_cat_names=True)\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    X_train = train[features]\n",
        "    if onehot:\n",
        "        X_train = encoder.fit_transform(X_train)\n",
        "    if scale:\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "    y_train = train[target]\n",
        "\n",
        "    X_test = test[features]\n",
        "    if onehot:\n",
        "        X_test = encoder.transform(X_test)\n",
        "    if scale:\n",
        "        X_test = scaler.transform(X_test)\n",
        "    y_test = test[target]\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def get_results(y_true, y_pred):\n",
        "    accuracy_metric = accuracy_score(y_true, y_pred)\n",
        "    roc_auc_metric = roc_auc_score(y_true, y_pred)\n",
        "    f1_metric = f1_score(y_true, y_pred)\n",
        "\n",
        "    print('-------------------------------')\n",
        "    print(f'Accuracy Score: {accuracy_metric}')\n",
        "    print(f'ROC AUC Score: {roc_auc_metric}')\n",
        "    print(f'F1 Score: {f1_metric}')\n",
        "    return\n",
        "\n",
        "# code credit to https://medium.com/@aakashgoel12/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "def get_f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n",
        "\n",
        "def clean_text(text):\n",
        "    tokens = re.sub('[^a-zA-Z 0-9]', '', text)\n",
        "    tokens = tokens.lower().split()\n",
        "    return tokens\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW0mGltgQUTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading the data\n",
        "'''\n",
        "df = load_data()\n",
        "df.head()\n",
        "'''\n",
        "df = pd.read_csv('/content/large_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhvjDvbmQUTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting variables\n",
        "batch_size = 32\n",
        "max_features = 10000\n",
        "features = 'name'\n",
        "target = 'final_status'\n",
        "maxlen= 10\n",
        "oov_token = max_features+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5-_5288ljxO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a94fa7e6-d469-4126-d313-00fde7bfd364"
      },
      "source": [
        "oov_token"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zod_MjydQUTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cleaning the data\n",
        "df[features] = df[features].fillna('')\n",
        "df[features] = df[features].apply(lambda x: clean_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "yTFwDCs2QUTu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "ede37a58-56db-4ae8-e00c-3b30d22ce949"
      },
      "source": [
        "# train/test split\n",
        "year = 2020\n",
        "train, test = my_split(df, year)\n",
        "\n",
        "# transforming words to integer values\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(train[features])\n",
        "\n",
        "train[features] = tokenizer.texts_to_sequences(train[features])\n",
        "test[features] = tokenizer.texts_to_sequences(test[features])\n",
        "\n",
        "# processing data\n",
        "X_train, y_train, X_test, y_test = model_prep(train, test, features, target, onehot=False, scale=False)\n",
        "#maxlen = max([len(each) for each in train[features]])\n",
        "\n",
        "# padding sequences to all be the same length\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=maxlen, padding='post')\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=maxlen, padding='post')\n",
        "\n",
        "# instantiating the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compiling the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy', get_f1])\n",
        "\n",
        "# fitting the model\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=batch_size, \n",
        "          epochs=5, \n",
        "          validation_data=(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/5\n",
            "9896/9896 [==============================] - 805s 81ms/step - loss: 0.6025 - accuracy: 0.6526 - get_f1: 0.5908 - val_loss: 0.5331 - val_accuracy: 0.6966 - val_get_f1: 0.7393\n",
            "Epoch 2/5\n",
            "9896/9896 [==============================] - 796s 80ms/step - loss: 0.5759 - accuracy: 0.6802 - get_f1: 0.6281 - val_loss: 0.5376 - val_accuracy: 0.6927 - val_get_f1: 0.7360\n",
            "Epoch 3/5\n",
            "9896/9896 [==============================] - 802s 81ms/step - loss: 0.5578 - accuracy: 0.6945 - get_f1: 0.6463 - val_loss: 0.5206 - val_accuracy: 0.7167 - val_get_f1: 0.7666\n",
            "Epoch 4/5\n",
            "9896/9896 [==============================] - 804s 81ms/step - loss: 0.5393 - accuracy: 0.7104 - get_f1: 0.6643 - val_loss: 0.5379 - val_accuracy: 0.6969 - val_get_f1: 0.7442\n",
            "Epoch 5/5\n",
            "9896/9896 [==============================] - 797s 80ms/step - loss: 0.5189 - accuracy: 0.7261 - get_f1: 0.6836 - val_loss: 0.5759 - val_accuracy: 0.6829 - val_get_f1: 0.7259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ire2cP2QUTz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "96cb174a-3dc1-44bd-8006-cfa369091b9c"
      },
      "source": [
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "y_true = y_test\n",
        "\n",
        "get_results(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------\n",
            "Accuracy Score: 0.6829078992756122\n",
            "ROC AUC Score: 0.7036824448399581\n",
            "F1 Score: 0.7415840888326658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl8F4XPAi26j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUIjOJ2IlvIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('basic_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNZrp44VpBmp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "1df7598f-d27d-4fb0-e36e-63fdbeb69e0f"
      },
      "source": [
        "# train/test split\n",
        "year = 2020\n",
        "train, test = my_split(df, year)\n",
        "\n",
        "# transforming words to integer values\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(train[features])\n",
        "\n",
        "train[features] = tokenizer.texts_to_sequences(train[features])\n",
        "test[features] = tokenizer.texts_to_sequences(test[features])\n",
        "\n",
        "# processing data\n",
        "X_train, y_train, X_test, y_test = model_prep(train, test, features, target, onehot=False, scale=False)\n",
        "#maxlen = max([len(each) for each in train[features]])\n",
        "\n",
        "# padding sequences to all be the same length\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=maxlen, padding='post')\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=maxlen, padding='post')\n",
        "\n",
        "# instantiating the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dropout(.1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compiling the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fitting the model\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=batch_size, \n",
        "          epochs=5, \n",
        "          validation_data=(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/5\n",
            "9896/9896 [==============================] - 782s 79ms/step - loss: 0.6053 - accuracy: 0.6505 - val_loss: 0.5512 - val_accuracy: 0.6814\n",
            "Epoch 2/5\n",
            "9896/9896 [==============================] - 816s 82ms/step - loss: 0.5778 - accuracy: 0.6787 - val_loss: 0.5524 - val_accuracy: 0.6895\n",
            "Epoch 3/5\n",
            "9896/9896 [==============================] - 829s 84ms/step - loss: 0.5605 - accuracy: 0.6932 - val_loss: 0.5270 - val_accuracy: 0.7046\n",
            "Epoch 4/5\n",
            "9896/9896 [==============================] - 838s 85ms/step - loss: 0.5418 - accuracy: 0.7092 - val_loss: 0.5546 - val_accuracy: 0.6887\n",
            "Epoch 5/5\n",
            "9896/9896 [==============================] - 835s 84ms/step - loss: 0.5217 - accuracy: 0.7254 - val_loss: 0.5704 - val_accuracy: 0.6866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSlMBlLhqbUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('basic_name_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVt5fm9U9yZY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "48e38e5b-1004-4acb-d4f6-c808e84986a2"
      },
      "source": [
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "y_true = y_test\n",
        "\n",
        "get_results(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------\n",
            "Accuracy Score: 0.6866160745084512\n",
            "ROC AUC Score: 0.7047922140294375\n",
            "F1 Score: 0.746051712089448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfiScvmY9zAJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "761b1492-6e28-435a-f118-2060c9830e07"
      },
      "source": [
        "# it appears that model was slightly better so training it with more epochs\n",
        "# train/test split\n",
        "year = 2020\n",
        "train, test = my_split(df, year)\n",
        "\n",
        "# transforming words to integer values\n",
        "tokenizer = Tokenizer(num_words=max_features, oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(train[features])\n",
        "\n",
        "train[features] = tokenizer.texts_to_sequences(train[features])\n",
        "test[features] = tokenizer.texts_to_sequences(test[features])\n",
        "\n",
        "# processing data\n",
        "X_train, y_train, X_test, y_test = model_prep(train, test, features, target, onehot=False, scale=False)\n",
        "#maxlen = max([len(each) for each in train[features]])\n",
        "\n",
        "# padding sequences to all be the same length\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=maxlen, padding='post')\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=maxlen, padding='post')\n",
        "\n",
        "# instantiating the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, \n",
        "               dropout=0.2, recurrent_dropout=0.3,\n",
        "               kernel_constraint=unit_norm(), recurrent_constraint=unit_norm()))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compiling the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
        "# fitting the model\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=batch_size, \n",
        "          epochs=25, \n",
        "          validation_data=(X_test,y_test),\n",
        "          callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/25\n",
            "9896/9896 [==============================] - 515s 52ms/step - loss: 0.6013 - accuracy: 0.6548 - val_loss: 0.5348 - val_accuracy: 0.6989\n",
            "Epoch 2/25\n",
            "9896/9896 [==============================] - 518s 52ms/step - loss: 0.5748 - accuracy: 0.6815 - val_loss: 0.5580 - val_accuracy: 0.6651\n",
            "Epoch 3/25\n",
            "9896/9896 [==============================] - 528s 53ms/step - loss: 0.5585 - accuracy: 0.6953 - val_loss: 0.5444 - val_accuracy: 0.6988\n",
            "Epoch 4/25\n",
            "9896/9896 [==============================] - 522s 53ms/step - loss: 0.5447 - accuracy: 0.7066 - val_loss: 0.5374 - val_accuracy: 0.7039\n",
            "Epoch 5/25\n",
            "9896/9896 [==============================] - 520s 52ms/step - loss: 0.5325 - accuracy: 0.7164 - val_loss: 0.5273 - val_accuracy: 0.7134\n",
            "Epoch 6/25\n",
            "9896/9896 [==============================] - 521s 53ms/step - loss: 0.5214 - accuracy: 0.7256 - val_loss: 0.5684 - val_accuracy: 0.6732\n",
            "Epoch 7/25\n",
            "9896/9896 [==============================] - 519s 52ms/step - loss: 0.5109 - accuracy: 0.7327 - val_loss: 0.6101 - val_accuracy: 0.6522\n",
            "Epoch 8/25\n",
            "9896/9896 [==============================] - 524s 53ms/step - loss: 0.5007 - accuracy: 0.7404 - val_loss: 0.5748 - val_accuracy: 0.6846\n",
            "Epoch 9/25\n",
            "1928/9896 [====>.........................] - ETA: 6:58 - loss: 0.4714 - accuracy: 0.7588"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_iI2Ra0-C9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('name_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F20n4FlbFv6X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "bb68111c-09be-414b-f746-ab10c0a842a6"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('name_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4213e6eb-314a-49ed-b96f-35560c041521\", \"name_model.h5\", 16997432)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URtVlOgKGB92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "eabab82b-9e1e-4373-afec-c62aa8b98ad9"
      },
      "source": [
        "with open('new_tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "files.download('new_tokenizer.pickle')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0d7274d3-d44e-45a7-9add-54293690cbeb\", \"new_tokenizer.pickle\", 6686756)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL41voBCGTOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}